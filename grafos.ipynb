{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grafos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luana-martins/Grafos/blob/main/grafos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wIWPBzzHatV"
      },
      "source": [
        "# Seleção de Features para a Classificação de Dados de Saúde\n",
        "## Jalisson Henrique, Luana Martins, Tiago Machado\n",
        "\n",
        "Este projeto contém a implementação do algoritmo proposto para a disciplina de Grafos. Além disso, para possibilitar a execução do experimento, foram implementados quatro modelos de Machine Learning (Decision-Tree, KNN, Random-Forest e SVM-Linear). Ainda, contém a implementação do algoritmo Sequential Feature Selection (SFS), também utilizado para a comparação com o JLT.\n",
        "\n",
        "**Importante:** \n",
        "\n",
        "*   *Configurar a Seção 6 conforme a execução que deseja!*\n",
        "*   *Para executar vá no menu superior dessa página em \"Ambiente de execução\" e selecione \"Executar tudo\".*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLYpSlFHudtc"
      },
      "source": [
        "# 1. Configuração do Ambiente\n",
        "\n",
        "Nesta seção, as bibliotecas e o dataset são importados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnLSFtQglZxP"
      },
      "source": [
        "#Importação das bibliotecas utilizadas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "#bibliotecas gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns;\n",
        " \n",
        "#bibliotecas de métricas\n",
        "import scipy.stats as stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from warnings import filterwarnings\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        " \n",
        "#Classificadores\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Algoritmos literatura\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENMBoI0faa6e"
      },
      "source": [
        "# 2. Dataset\n",
        "\n",
        "Nesta seção, o dataset é importado e descrito por meio de estatísticas descritivas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0HF7VUVqk3_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "e810be53-b129-4885-8e4d-acdc8ae9ea82"
      },
      "source": [
        "#Importação do dataset para variável 'dados'\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/luana-martins/Grafos/main/data.csv');\n",
        "\n",
        "# Tratamento da label - M por (1), B por (0)\n",
        "dataset['diagnosis'] = dataset['diagnosis'].replace('M',1)\n",
        "dataset['diagnosis'] = dataset['diagnosis'].replace('B',0)\n",
        "\n",
        "#Estatística básica do dataset\n",
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>0.627417</td>\n",
              "      <td>706.771388</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>4.304801</td>\n",
              "      <td>4.835984</td>\n",
              "      <td>7.489124</td>\n",
              "      <td>2.366459</td>\n",
              "      <td>16.965766</td>\n",
              "      <td>0.851112</td>\n",
              "      <td>77.138555</td>\n",
              "      <td>825.490173</td>\n",
              "      <td>2549.980718</td>\n",
              "      <td>316.226116</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.176469</td>\n",
              "      <td>1.153794</td>\n",
              "      <td>0.067979</td>\n",
              "      <td>0.231228</td>\n",
              "      <td>0.014329</td>\n",
              "      <td>315.194921</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>10.633281</td>\n",
              "      <td>25.259112</td>\n",
              "      <td>26.723742</td>\n",
              "      <td>8.745685</td>\n",
              "      <td>30.367174</td>\n",
              "      <td>1.964313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>0.483918</td>\n",
              "      <td>2430.243368</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>21.074558</td>\n",
              "      <td>26.827478</td>\n",
              "      <td>35.618994</td>\n",
              "      <td>16.155145</td>\n",
              "      <td>53.846023</td>\n",
              "      <td>7.103493</td>\n",
              "      <td>277.327735</td>\n",
              "      <td>832.741506</td>\n",
              "      <td>1757.074266</td>\n",
              "      <td>1532.270716</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>1.678798</td>\n",
              "      <td>17.470924</td>\n",
              "      <td>0.784389</td>\n",
              "      <td>2.112944</td>\n",
              "      <td>0.251388</td>\n",
              "      <td>1655.459336</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>37.236433</td>\n",
              "      <td>96.473015</td>\n",
              "      <td>114.204035</td>\n",
              "      <td>39.465975</td>\n",
              "      <td>90.748044</td>\n",
              "      <td>14.464355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.760000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116700</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.771400</td>\n",
              "      <td>10.080000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.210000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086410</td>\n",
              "      <td>0.065260</td>\n",
              "      <td>0.029580</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.057800</td>\n",
              "      <td>0.236600</td>\n",
              "      <td>0.856100</td>\n",
              "      <td>1491.000000</td>\n",
              "      <td>18.520000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013150</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015180</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.180000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>0.150700</td>\n",
              "      <td>0.116800</td>\n",
              "      <td>0.064990</td>\n",
              "      <td>0.254900</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.850000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095940</td>\n",
              "      <td>0.094620</td>\n",
              "      <td>0.063870</td>\n",
              "      <td>0.033900</td>\n",
              "      <td>0.181400</td>\n",
              "      <td>0.061660</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>1025.000000</td>\n",
              "      <td>2155.000000</td>\n",
              "      <td>25.790000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020620</td>\n",
              "      <td>0.026020</td>\n",
              "      <td>0.010970</td>\n",
              "      <td>0.018780</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>15.150000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.133800</td>\n",
              "      <td>0.227900</td>\n",
              "      <td>0.249200</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>0.288400</td>\n",
              "      <td>0.080060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>17.680000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.106100</td>\n",
              "      <td>0.132500</td>\n",
              "      <td>0.142500</td>\n",
              "      <td>0.077260</td>\n",
              "      <td>0.203600</td>\n",
              "      <td>0.066400</td>\n",
              "      <td>0.585800</td>\n",
              "      <td>1424.000000</td>\n",
              "      <td>3176.000000</td>\n",
              "      <td>49.850000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032880</td>\n",
              "      <td>0.042560</td>\n",
              "      <td>0.014930</td>\n",
              "      <td>0.023700</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>19.850000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.384200</td>\n",
              "      <td>0.431600</td>\n",
              "      <td>0.170800</td>\n",
              "      <td>0.331800</td>\n",
              "      <td>0.092110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9904.000000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>313.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>2873.000000</td>\n",
              "      <td>4885.000000</td>\n",
              "      <td>9807.000000</td>\n",
              "      <td>9833.000000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>396.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9981.000000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>1058.000000</td>\n",
              "      <td>1252.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>544.000000</td>\n",
              "      <td>173.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id   diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02  569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    0.627417  ...       30.367174                 1.964313\n",
              "std    1.250206e+08    0.483918  ...       90.748044                14.464355\n",
              "min    8.670000e+03    0.000000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    0.000000  ...        0.254900                 0.071460\n",
              "50%    9.060240e+05    1.000000  ...        0.288400                 0.080060\n",
              "75%    8.813129e+06    1.000000  ...        0.331800                 0.092110\n",
              "max    9.113205e+08    1.000000  ...      544.000000               173.000000\n",
              "\n",
              "[8 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SliJMFGssnFu"
      },
      "source": [
        "# 3. Classificadores\n",
        "\n",
        "Nesta seção, são implementados os classificadores utilizados para o experimento, que são: (1) Classificador Linear, (2) Random-Forest, (3) KNN, e (4) Decision Tree. **Execute aqueles que deseja verificar**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt3oKGm1y-7g"
      },
      "source": [
        "# (1) Classificador Linear \n",
        "# O que de fato queremos é uma função f([X1,X2,X3,Xn]) que nos retorne M (1) - Maligno ou B (0) - Benigno\n",
        "\n",
        "# Recebe as entradas e o label para equação y = xi + e\n",
        "def ClassificadorLinear(conjunto, imprimir):\n",
        "  filterwarnings('ignore')\n",
        "\n",
        "  y = dataset['diagnosis']\n",
        "  x = []\n",
        "  for variavel in conjunto:\n",
        "    x.append(dataset[variavel])\n",
        "  x = np.reshape(x, (len(conjunto), len(dataset))).T\n",
        "  \n",
        "  # Cria o modelo de machine learning (SVM)\n",
        "  modelo = LinearSVC()\n",
        "\n",
        "  # Divide o dataset em dados de treino e teste, com 70% treino e 30% teste\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(x,y, train_size= .3, random_state = 0)\n",
        "\n",
        "  # Treina o modelo criado\n",
        "  modelo.fit(treino_x, treino_y)\n",
        "\n",
        "  # Colhe o resultado do modelo ao dataset de teste \n",
        "  previsoes = modelo.predict(teste_x)\n",
        "  acuracia = (accuracy_score(teste_y, previsoes) * 100)\n",
        "\n",
        "  # Imprime os resultados de acurácia\n",
        "  if imprimir:\n",
        "    print(\"A acurácia do algoritmo de baseline foi %.2f%%\" % acuracia)\n",
        "    print(\"Quantidade de features selecionadas: \", len(conjunto))\n",
        "    print(\"Lista de features selecioandas: \", conjunto)\n",
        "    print('\\n[Classification Report] SVM-kernel-linear')\n",
        "    print( classification_report(teste_y, previsoes))\n",
        "\n",
        "    # Matriz de confusão\n",
        "    pd.DataFrame(confusion_matrix(teste_y, previsoes),\n",
        "                index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])\n",
        "  \n",
        "  return acuracia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_btsAbSa0BD0"
      },
      "source": [
        "# (2) Modelo RandomForest\r\n",
        "\r\n",
        "# Recebe as entradas e o label para equação y = xi + e\r\n",
        "def ModeloRandomForest(conjunto, imprimir):\r\n",
        "  filterwarnings('ignore')\r\n",
        "\r\n",
        "  y = dataset['diagnosis']\r\n",
        "  x = []\r\n",
        "  for variavel in conjunto:\r\n",
        "    x.append(dataset[variavel])\r\n",
        "  x = np.reshape(x, (len(conjunto), len(dataset))).T\r\n",
        "\r\n",
        "  # Cria o modelo de machine learning (RandomForest)\r\n",
        "  modelo = RandomForestClassifier(n_estimators=100)\r\n",
        "\r\n",
        "  # Divide o dataset em dados de treino e teste, com 70% treino e 30% teste\r\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(x,y, train_size= .3)\r\n",
        "\r\n",
        "  # Treina o modelo criado\r\n",
        "  modelo.fit(treino_x, treino_y)\r\n",
        "\r\n",
        "  # Colhe o resultado do modelo ao dataset de teste \r\n",
        "  previsoes = modelo.predict(teste_x)\r\n",
        "  acuracia = (accuracy_score(teste_y, previsoes) * 100)\r\n",
        "\r\n",
        "  # Imprime os resultados de acurácia\r\n",
        "  if imprimir:\r\n",
        "    print(\"A acurácia do algoritmo de baseline foi %.2f%%\" % acuracia)\r\n",
        "    print(\"Quantidade de features selecionadas: \", len(conjunto))\r\n",
        "    print(\"Lista de features selecioandas: \", conjunto) \r\n",
        "    print('\\n[Classification Report] Random-Forest')\r\n",
        "    print( classification_report(teste_y, previsoes))\r\n",
        "\r\n",
        "    # Matriz de confusão\r\n",
        "    pd.DataFrame(confusion_matrix(teste_y, previsoes),\r\n",
        "                index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])\r\n",
        "  \r\n",
        "  return acuracia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piZl5hMA6aHb"
      },
      "source": [
        "# (3) Classificador KNeighbors\r\n",
        "\r\n",
        "#1. Recebe as entradas e o label para equação y = xi + e\r\n",
        "def ModeloKNeighbors(conjunto, imprimir):\r\n",
        "  filterwarnings('ignore')\r\n",
        "\r\n",
        "  y = dataset['diagnosis']\r\n",
        "  x = []\r\n",
        "  for variavel in conjunto:\r\n",
        "    x.append(dataset[variavel])\r\n",
        "  x = np.reshape(x, (len(conjunto), len(dataset))).T\r\n",
        "  \r\n",
        "  # Cria o modelo de machine learning (knn)\r\n",
        "  modelo = KNeighborsClassifier(n_neighbors=3) #n_neighbors=3 (número de vizinhos)\r\n",
        "\r\n",
        "  # Divide o dataset em dados de treino e teste, com 70% treino e 30% teste\r\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(x,y, train_size= .3)\r\n",
        "\r\n",
        "  # Treina o modelo criado\r\n",
        "  modelo.fit(treino_x, treino_y)\r\n",
        "\r\n",
        "  # Colhe o resultado do modelo ao dataset de teste \r\n",
        "  previsoes = modelo.predict(teste_x)\r\n",
        "  acuracia = (accuracy_score(teste_y, previsoes) * 100)\r\n",
        "\r\n",
        "  # Imprime os resultados de acurácia\r\n",
        "  if imprimir:\r\n",
        "    print(\"A acurácia do algoritmo de baseline foi %.2f%%\" % acuracia)\r\n",
        "    print(\"Quantidade de features selecionadas: \", len(conjunto))\r\n",
        "    print(\"Lista de features selecioandas: \", conjunto)\r\n",
        "    print('\\n[Classification Report] KNN')\r\n",
        "    print( classification_report(teste_y, previsoes))\r\n",
        "\r\n",
        "    # Matriz de confusão\r\n",
        "    pd.DataFrame(confusion_matrix(teste_y, previsoes),\r\n",
        "                index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])\r\n",
        "  \r\n",
        "  return acuracia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kZQsehO9NFv"
      },
      "source": [
        "# (4) Modelo DecisionTree\r\n",
        "\r\n",
        "# Recebe as entradas e o label para equação y = xi + e\r\n",
        "def ModeloDecisionTree(conjunto, imprimir):\r\n",
        "  filterwarnings('ignore')\r\n",
        "\r\n",
        "  y = dataset['diagnosis']\r\n",
        "  x = []\r\n",
        "  for variavel in conjunto:\r\n",
        "    x.append(dataset[variavel])\r\n",
        "  x = np.reshape(x, (len(conjunto), len(dataset))).T\r\n",
        "  \r\n",
        "  # Cria o modelo de machine learning (DecisionTree)\r\n",
        "  modelo = DecisionTreeClassifier()\r\n",
        "\r\n",
        "  # Divide o dataset em dados de treino e teste, com 70% treino e 30% teste\r\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(x,y, train_size= .3)\r\n",
        "\r\n",
        "  # Treina o modelo criado\r\n",
        "  modelo.fit(treino_x, treino_y)\r\n",
        "\r\n",
        "  # Colhe o resultado do modelo ao dataset de teste \r\n",
        "  previsoes = modelo.predict(teste_x)\r\n",
        "  acuracia = (accuracy_score(teste_y, previsoes) * 100)\r\n",
        "\r\n",
        "  # Imprime os resultados de acurácia\r\n",
        "  if imprimir:\r\n",
        "    print(\"A acurácia do algoritmo de baseline foi %.2f%%\" % acuracia)\r\n",
        "    print(\"Quantidade de features selecionadas: \", len(conjunto))\r\n",
        "    print(\"Lista de features selecioandas: \", conjunto)    \r\n",
        "    print('\\n[Classification Report] Decision-Tree')\r\n",
        "    print( classification_report(teste_y, previsoes))\r\n",
        "\r\n",
        "    # Matriz de confusão\r\n",
        "    pd.DataFrame(confusion_matrix(teste_y, previsoes),\r\n",
        "                index=['neg', 'pos'], columns=['pred_neg', 'pred_pos'])\r\n",
        "  \r\n",
        "  return acuracia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5UxYM-p7ViU"
      },
      "source": [
        "# 4. Algoritmo de Seleção de feature - SFS\n",
        "\n",
        "Nesta seção, é apresentada a implementação do algoritmo Sequential Feature Selection. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Hx6NFs7xuf"
      },
      "source": [
        "# (1) Sequential Feature Selection\n",
        "\n",
        "def SequentialFeatureSelection(conjunto, classificador):\n",
        "  filterwarnings('ignore')\n",
        "\n",
        "  y = dataset['diagnosis']\n",
        "  x = []\n",
        "  for variavel in conjunto:\n",
        "    x.append(dataset[variavel])\n",
        "  x = np.reshape(x, (len(conjunto), len(dataset))).T\n",
        "\n",
        "  # Divide o dataset em dados de treino e teste, com 70% treino e 30% teste\n",
        "  treino_x, teste_x, treino_y, teste_y = train_test_split(x,y, train_size= .3)\n",
        "  treino_x.shape, teste_x.shape\n",
        "\n",
        "  feature_names = conjunto  \n",
        "  # chama o algoritmo para seleção de features e treina o modelo\n",
        "  if classificador == \"classificadorLinear\":\n",
        "    sfs = SFS(LinearSVC(random_state=0),\n",
        "              k_features = (1, len(conjunto)),\n",
        "              forward= True,\n",
        "              floating = False,\n",
        "              verbose= 2,\n",
        "              scoring= 'accuracy',\n",
        "              cv = 4,\n",
        "              n_jobs= -1\n",
        "              )\n",
        "    sfs.fit(treino_x, treino_y,  custom_feature_names=feature_names)\n",
        "    features = np.array(sfs.k_feature_names_)\n",
        "    ClassificadorLinear(features, True)\n",
        "\n",
        "  if classificador == \"classificadorRandomForest\":\n",
        "    sfs = SFS(RandomForestClassifier(n_estimators=100),\n",
        "              k_features = (1, len(conjunto)),\n",
        "              forward= True,\n",
        "              floating = False,\n",
        "              verbose= 2,\n",
        "              scoring= 'accuracy',\n",
        "              cv = 4,\n",
        "              n_jobs= -1\n",
        "              )\n",
        "    sfs.fit(treino_x, treino_y,  custom_feature_names=feature_names)\n",
        "    features = np.array(sfs.k_feature_names_)\n",
        "    ModeloRandomForest(features, True)\n",
        "\n",
        "  if classificador == \"classificadorDecisionTree\":\n",
        "    sfs = SFS(DecisionTreeClassifier(),\n",
        "              k_features = (1, len(conjunto)),\n",
        "              forward= True,\n",
        "              floating = False,\n",
        "              verbose= 2,\n",
        "              scoring= 'accuracy',\n",
        "              cv = 4,\n",
        "              n_jobs= -1\n",
        "              )\n",
        "    sfs.fit(treino_x, treino_y,  custom_feature_names=feature_names)\n",
        "    features = np.array(sfs.k_feature_names_)\n",
        "    ModeloDecisionTree(features, True)\n",
        "\n",
        "  if classificador == \"classificadorKNN\": \n",
        "    sfs = SFS(KNeighborsClassifier(n_neighbors=3),\n",
        "              k_features = (1, len(conjunto)),\n",
        "              forward= True,\n",
        "              floating = False,\n",
        "              verbose= 2,\n",
        "              scoring= 'accuracy',\n",
        "              cv = 4,\n",
        "              n_jobs= -1\n",
        "              )\n",
        "    sfs.fit(treino_x, treino_y,  custom_feature_names=feature_names)\n",
        "    features = np.array(sfs.k_feature_names_)\n",
        "    ModeloKNeighbors(features, True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJXAoowdvjK4"
      },
      "source": [
        "# 5. O Algoritmo Proposto\n",
        "Nesta seção, apresentamos nossa proposta, o algoritmo **JLT**. Ele consiste na aplicação do método filter e do método wrapper para a seleção de um conjunto de features. Eles são combinados em duas etapas. Na primeira etapa, **Tupla Solução**, o método filter calcula a correlação entre label-features para selecionar uma dupla de features <forte, fraco>. O resultado desse filtro serve como entrada para o método wrapper que classifica cada dupla <forte, fraco> para escolher uma promissora. Na segunda etapa, **Conjunto Solução**, o método filtro é aplicado para selecionar um conjunto de features complementares à Tupla Solução. Os resultados desse filtro são utilizados como entrada no método wrapper, que classifica as features complementares para selecionar o conjunto final necessário para treinar o modelo. **Para execução do algoritmo JLT, execute esta seção e configure a Seção 6!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkwO8lVXV7Gr"
      },
      "source": [
        "def JLT():\n",
        "\n",
        "  ######### TuplaSolução: seleciona uma tupla<forte, fraco> como solução inicial\n",
        "  correlacaoForteLabel = []\n",
        "  correlacaoFracaLabel = []\n",
        "  \n",
        "  #### Filter pt 1\n",
        "  # Cria listas de correlações, entre label e cada coluna do dataset\n",
        "  for coluna in dataset:\n",
        "\n",
        "    # As correlações entre label-label e label-id não são necessárias\n",
        "    if (coluna != 'diagnosis') and (coluna != 'id'):\n",
        "\n",
        "      # O teste de Spearman é usado para distribuições normais e não normais\n",
        "      coef, p_value = stats.spearmanr(dataset['diagnosis'], dataset[coluna])\n",
        "      coef = abs(coef)\n",
        "\n",
        "      # Insere a correlação na lista correspondente\n",
        "      if (coef >= 0 and coef <= 0.4):\n",
        "        correlacaoFracaLabel.append([coluna, coef])\n",
        "      if (coef >= 0.6 and coef <= 1):\n",
        "        correlacaoForteLabel.append([coluna, coef])\n",
        "\n",
        "  # Ordena das correlações para facilitar a montagem de tuplas<forte, fraco>\n",
        "  correlacaoForteLabel.sort(key=lambda tup: tup[1], reverse=True)\n",
        "  correlacaoFracaLabel.sort(key=lambda tup: tup[1])\n",
        "\n",
        "  #### Wrapper pt 1\n",
        "  featuresJaAnalisadas = []\n",
        "  solucaoOtima = 0.0\n",
        "  conjuntoSolucao = []\n",
        "\n",
        "  # Percorre as features fortes em ordem decrescente\n",
        "  for forte in correlacaoForteLabel:\n",
        "\n",
        "    # Se a feature já foi analisada como forte/fraca, não deve ser analisada novamente\n",
        "    if forte[0] not in featuresJaAnalisadas:\n",
        "      featuresJaAnalisadas.append(forte[0])\n",
        "\n",
        "    # Percorre as features fracas em ordem crescente\n",
        "    for fraco in correlacaoFracaLabel:\n",
        "      \n",
        "      # Se a feature já foi analisada como forte/fraca, não deve ser analisada novamente\n",
        "      if fraco[0] not in featuresJaAnalisadas:\n",
        "        featuresJaAnalisadas.append(fraco[0])\n",
        "      \n",
        "      # Cria duplas forte-fraco\n",
        "      solucaoInicial = []\n",
        "      solucaoInicial.append([forte[0], fraco[0]])\n",
        "      ultimaPosicao = len(solucaoInicial)-1\n",
        "\n",
        "      # Calcula a acurácia e, enquanto o novo conjunto melhorar o valor da acurácia, o conjuntoSolucao é atualizado\n",
        "      acuracia = Classificador(solucaoInicial[ultimaPosicao], False)\n",
        "      if acuracia > solucaoOtima:\n",
        "        solucaoOtima = acuracia\n",
        "        conjuntoSolucao.append([solucaoInicial, solucaoOtima])\n",
        "      else:\n",
        "        break\n",
        "  \n",
        "\n",
        "  ######### ConjuntoSolução: seleciona o conjunto final de features\n",
        "\n",
        "  ### Filter pt 2 \n",
        "  ultimaPosicao = len(conjuntoSolucao)-1\n",
        "  tupla = conjuntoSolucao[ultimaPosicao]\n",
        "  solucaoNova = [tupla[0][0][0], tupla[0][0][1]]\n",
        "  featuresCandidatas = []\n",
        "  \n",
        "  feature_forte_normalidade = verificaDistribuicao(dataset[solucaoNova[0]]) \n",
        "  feature_fraca_normalidade = verificaDistribuicao(dataset[solucaoNova[0]])\n",
        "\n",
        "  # Percorre features ainda não analisadas \n",
        "  for feature in dataset:\n",
        "    propriedade_nao_linearidade = True \n",
        "    propriedade_nao_negatividade = True\n",
        "    coef_feature_forte = 0\n",
        "    coef_feature_fraca = 0\n",
        "\n",
        "    if (feature not in featuresJaAnalisadas) and (feature != 'diagnosis') and (feature != 'id'): \n",
        "\n",
        "      # Dados não-normais satisfazem não linearidade, porque não é possivel aplicar Pearson\n",
        "      if (not feature_forte_normalidade) or (not feature_fraca_normalidade):\n",
        "        coef_feature_forte, p_value = stats.spearmanr(dataset[solucaoNova[0]], dataset[feature])\n",
        "        coef_feature_fraca, p_value = stats.spearmanr(dataset[solucaoNova[1]], dataset[feature])\n",
        "\n",
        "      # Dados normais devem ter correlação igual a 0 para satisfazer linearidade\n",
        "      if (feature_forte_normalidade) and (feature_fraca_normalidade):\n",
        "        feature_complementar = verificaDistribuicao(dataset[feature])\n",
        "        coef_feature_forte, coef_feature_fraca\n",
        "\n",
        "        # Feature complementar também deve ter distribuição normal\n",
        "        if (feature_complementar):\n",
        "          coef_feature_forte, p_value = stats.pearsonr(dataset[solucaoNova[0]], dataset[feature])\n",
        "          coef_feature_fraca, p_value = stats.pearsonr(dataset[solucaoNova[1]], dataset[feature])\n",
        "          \n",
        "          # Se for diferente de 0 é porque há uma correlação linear \n",
        "          if (coef_feature_forte != 0) and (coef_feature_fraca != 0):\n",
        "            propriedade_nao_linear = False          \n",
        "      \n",
        "      # Propriedade de não-negatividade para distribuição não-normal\n",
        "      if (coef_feature_forte < 0) and (coef_feature_fraca < 0):\n",
        "          propriedade_nao_negatividade = False\n",
        "\n",
        "      # Se as propriedades de não-linearidade e não-negatividade são satisfeitas, tentar adicionar a feture no conjunto\n",
        "      if (propriedade_nao_negatividade and propriedade_nao_linearidade):\n",
        "        featuresCandidatas.append([feature, max(coef_feature_forte, coef_feature_fraca)])\n",
        "\n",
        "\n",
        "  featuresCandidatas.sort(key=lambda tup: tup[1])\n",
        "  ### Wrapper pt 2\n",
        "  for feature in featuresCandidatas:\n",
        "    solucaoNova.append(feature[0])\n",
        "    acuracia = Classificador(solucaoNova, False)\n",
        "    if acuracia > solucaoOtima:\n",
        "      solucaoOtima = acuracia\n",
        "      conjuntoSolucao.append([solucaoNova, solucaoOtima])\n",
        "    else:\n",
        "      solucaoNova.pop()\n",
        "\n",
        "  Classificador(solucaoNova, True)\n",
        "\n",
        "\n",
        "# Função para verificar distribuicao dos dados\n",
        "def verificaDistribuicao(amostra):\n",
        "  media = np.mean(amostra)\n",
        "  std = np.std(amostra)\n",
        "\n",
        "  # A normalidade é verificada por meio do teste de Kolmogorov-Smirnov\n",
        "  ks_stat, ks_p_valor = stats.kstest(amostra, cdf='norm', args=(media, std), N = len(dataset))   \n",
        "  \n",
        "  # Se o p-valor as ks_stat for menor ou igual que 0.05, então a distribuição não é normal\n",
        "  if ks_stat <= 0.05:\n",
        "    return 0\n",
        "  return 1     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQbmp2RYe1Cb"
      },
      "source": [
        "#6. Configuração\n",
        "Nesta seção, a execução do projeto deve ser configurada. Primeiramente, deve ser realizada a **(1) Seleção do Classificador**, onde um dos classificadores devem ser marcados como True: SVM-Linear, Random-Forest, KNN ou Decision-Tree. Em seguida, deve ser configurado o modo como o classificador será executado em **(2) Seleção de Features**, onde pode uma das opções deve ser marcada como True: execução do algoritmo proposto JLT, execução sem seleção de features, execução do SFS.\n",
        "\n",
        "**Marque apenas uma opção como TRUE no bloco (1) e outra no bloco (2)!**\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPMMM_buzLRf"
      },
      "source": [
        "# (1) Seleção do classificador a ser executado, selecione 1 por vez! \n",
        "classificadorLinear = False\n",
        "classificadorDecisionTree = False\n",
        "classificadorRandomForest = False\n",
        "classificadorKNN = True\n",
        "\n",
        "# (2) Seleção de como rodar o classificador, selecione 1 por vez!\n",
        "semSelecaoDeFeatures = False\n",
        "selecaoDeFeaturesJLT = True\n",
        "selecaoDeFeaturesSFS = False\n",
        "\n",
        "\n",
        "# Função para executar a configuração selecionada\n",
        "def Classificador(conjunto, imprimir):\n",
        "\n",
        "  if classificadorLinear:\n",
        "    return ClassificadorLinear(conjunto, imprimir)\n",
        "  \n",
        "  if classificadorRandomForest:\n",
        "    return ModeloRandomForest(conjunto, imprimir)\n",
        "  \n",
        "  if classificadorKNN:\n",
        "    return ModeloKNeighbors(conjunto, imprimir)\n",
        "  \n",
        "  if classificadorDecisionTree: \n",
        "    return ModeloDecisionTree(conjunto, imprimir)\n",
        "\n",
        "# Função para executar o modo selecionado\n",
        "def ModoExecucao():\n",
        "  lista = []\n",
        "  for feature in dataset:\n",
        "    if (feature != 'diagnosis') and (feature != 'id'):\n",
        "      lista.append(feature)\n",
        "  \n",
        "  if semSelecaoDeFeatures:\n",
        "    Classificador(lista, True)\n",
        "  \n",
        "  if selecaoDeFeaturesJLT:\n",
        "    JLT()\n",
        "\n",
        "  if selecaoDeFeaturesSFS:\n",
        "    if classificadorLinear:\n",
        "      SequentialFeatureSelection(lista, \"classificadorLinear\")\n",
        "    if classificadorRandomForest:\n",
        "      SequentialFeatureSelection(lista, \"classificadorRandomForest\")\n",
        "    if classificadorKNN:\n",
        "      SequentialFeatureSelection(lista, \"classificadorKNN\")\n",
        "    if classificadorDecisionTree:\n",
        "      SequentialFeatureSelection(lista, \"classificadorDecisionTree\")\n",
        "\n",
        "\n",
        "ModoExecucao()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}